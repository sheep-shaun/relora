{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:01:01.376482Z",
     "iopub.status.busy": "2024-06-02T21:01:01.375920Z",
     "iopub.status.idle": "2024-06-02T21:01:01.381926Z",
     "shell.execute_reply": "2024-06-02T21:01:01.381428Z",
     "shell.execute_reply.started": "2024-06-02T21:01:01.376461Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:01:01.383018Z",
     "iopub.status.busy": "2024-06-02T21:01:01.382569Z",
     "iopub.status.idle": "2024-06-02T21:01:01.386103Z",
     "shell.execute_reply": "2024-06-02T21:01:01.385658Z",
     "shell.execute_reply.started": "2024-06-02T21:01:01.382999Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_length = 128\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 8\n",
    "global_batch_size = 512\n",
    "accumulation_steps = global_batch_size / batch_size\n",
    "\n",
    "learning_rate = 1e-4\n",
    "betas = (0.9, 0.95)\n",
    "eps = 1e-8\n",
    "gradient_clipping = 1.0\n",
    "weight_decay = 0.1\n",
    "\n",
    "warmup_iters = 256\n",
    "\n",
    "train_iters = 2048\n",
    "\n",
    "model_name = \"EleutherAI/pythia-14m\"\n",
    "model_revision = \"step0\"\n",
    "\n",
    "dataset_path = \"allenai/c4\"\n",
    "dataset_name = \"realnewslike\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:01:01.387560Z",
     "iopub.status.busy": "2024-06-02T21:01:01.387394Z",
     "iopub.status.idle": "2024-06-02T21:01:12.888299Z",
     "shell.execute_reply": "2024-06-02T21:01:12.887759Z",
     "shell.execute_reply.started": "2024-06-02T21:01:01.387543Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361b7ee628a94b378a019e40de0a5033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1700a78acee5440190291102b0124fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25cbc456d62438dbefdc6e1970360d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_path, dataset_name)\n",
    "dataset = dataset.with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:01:12.889263Z",
     "iopub.status.busy": "2024-06-02T21:01:12.888985Z",
     "iopub.status.idle": "2024-06-02T21:01:12.891906Z",
     "shell.execute_reply": "2024-06-02T21:01:12.891457Z",
     "shell.execute_reply.started": "2024-06-02T21:01:12.889243Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:01:12.892658Z",
     "iopub.status.busy": "2024-06-02T21:01:12.892501Z",
     "iopub.status.idle": "2024-06-02T21:01:13.125909Z",
     "shell.execute_reply": "2024-06-02T21:01:13.125376Z",
     "shell.execute_reply.started": "2024-06-02T21:01:12.892641Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, revision=model_revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:01:13.127032Z",
     "iopub.status.busy": "2024-06-02T21:01:13.126595Z",
     "iopub.status.idle": "2024-06-02T21:07:44.221772Z",
     "shell.execute_reply": "2024-06-02T21:07:44.221285Z",
     "shell.execute_reply.started": "2024-06-02T21:01:13.127012Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dade79e9b414e1e9358a2e574a0d906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=60):   0%|          | 0/13799838 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 55714358\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 55063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(data):\n",
    "    outputs = tokenizer(\n",
    "        data[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = list()\n",
    "    # deleting samples shorter than context_length tokens\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize, batched=True, remove_columns=dataset[\"train\"].column_names, num_proc=60\n",
    ")\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:07:44.222661Z",
     "iopub.status.busy": "2024-06-02T21:07:44.222486Z",
     "iopub.status.idle": "2024-06-02T21:07:44.225462Z",
     "shell.execute_reply": "2024-06-02T21:07:44.225034Z",
     "shell.execute_reply.started": "2024-06-02T21:07:44.222641Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "val_dataset = tokenized_dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:07:56.497721Z",
     "iopub.status.busy": "2024-06-02T21:07:56.497152Z",
     "iopub.status.idle": "2024-06-02T21:07:56.501566Z",
     "shell.execute_reply": "2024-06-02T21:07:56.501092Z",
     "shell.execute_reply.started": "2024-06-02T21:07:56.497700Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=num_workers,\n",
    "                              worker_init_fn=seed_worker,\n",
    "                              generator=g)\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=num_workers,\n",
    "                            worker_init_fn=seed_worker,\n",
    "                            generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optim reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:42:26.052579Z",
     "iopub.status.busy": "2024-06-02T21:42:26.051926Z",
     "iopub.status.idle": "2024-06-02T21:42:26.056774Z",
     "shell.execute_reply": "2024-06-02T21:42:26.056268Z",
     "shell.execute_reply.started": "2024-06-02T21:42:26.052554Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def random_pruning_(tensor, prune_ratio):\n",
    "    \"\"\"\n",
    "    Performs random pruning dimensionality reduction **inplace**.\n",
    "    Only reduces the inner dimensionality, does not affect the shape of the tensor\n",
    "    \"\"\"\n",
    "    random_pruning_mask = torch.rand_like(tensor) > prune_ratio\n",
    "    tensor.mul_(random_pruning_mask)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def magnitude_pruning_(tensor, prune_ratio):\n",
    "    \"\"\"\n",
    "    Performs magnitude pruning dimensionality reduction **inplace**.\n",
    "    Only reduces the inner dimensionality, does not affect the shape of the tensor\n",
    "    \"\"\"\n",
    "    tensor_magnitude = torch.abs(tensor)\n",
    "    threshold = torch.quantile(tensor_magnitude.flatten().to(dtype=torch.float32), prune_ratio).to(dtype=tensor.dtype)\n",
    "\n",
    "    mask = tensor_magnitude > threshold\n",
    "    tensor.mul_(mask.to(dtype=tensor.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:49:57.535360Z",
     "iopub.status.busy": "2024-06-02T21:49:57.534727Z",
     "iopub.status.idle": "2024-06-02T21:49:57.759872Z",
     "shell.execute_reply": "2024-06-02T21:49:57.759290Z",
     "shell.execute_reply.started": "2024-06-02T21:49:57.535334Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch.distributed.optim import ZeroRedundancyOptimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:56:45.192101Z",
     "iopub.status.busy": "2024-06-02T21:56:45.191349Z",
     "iopub.status.idle": "2024-06-02T21:56:45.198582Z",
     "shell.execute_reply": "2024-06-02T21:56:45.198063Z",
     "shell.execute_reply.started": "2024-06-02T21:56:45.192074Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimizer_reset(\n",
    "    optimizer,\n",
    "    *,\n",
    "    reset_params: list[torch.nn.Parameter],\n",
    "    optimizer_state_keys: list[str],\n",
    "    reset_optimizer_on_relora: bool,\n",
    "    optimizer_random_pruning: float,\n",
    "    optimizer_magnitude_pruning: float,\n",
    "):\n",
    "    \"\"\"\n",
    "        optimizer_state_keys: e.g., [\"exp_avg\", \"exp_avg_sq\"]\n",
    "    \"\"\"\n",
    "    n_reset_types = (\n",
    "        int(bool(reset_optimizer_on_relora))\n",
    "        + int(bool(optimizer_random_pruning))\n",
    "        + int(bool(optimizer_magnitude_pruning))\n",
    "    )\n",
    "    if n_reset_types != 1:\n",
    "        # logger.warning(f\"Got {reset_optimizer_on_relora=}, {optimizer_random_pruning=}, \"\n",
    "        #                f\"{optimizer_magnitude_pruning=}\")\n",
    "        raise ValueError(f\"Exactly one of reset_optimizer_on_relora, \"\n",
    "                         f\"optimizer_random_pruning, optimizer_magnitude_pruning must be True\")\n",
    "\n",
    "    # pruning_fn has to be inplace to work with ZeroRedundancyOptimizer\n",
    "    if reset_optimizer_on_relora:\n",
    "        pruning_fn = partial(random_pruning_, prune_ratio=0.999)\n",
    "    elif optimizer_random_pruning:\n",
    "        pruning_fn = partial(random_pruning_, prune_ratio=optimizer_random_pruning)\n",
    "    elif optimizer_magnitude_pruning:\n",
    "        pruning_fn = partial(magnitude_pruning_, prune_ratio=optimizer_magnitude_pruning)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown pruning type\")\n",
    "        \n",
    "    n_zeros = 0\n",
    "    n_total = 0\n",
    "\n",
    "    optimizer_state = optimizer.state\n",
    "    if isinstance(optimizer, ZeroRedundancyOptimizer):\n",
    "        optimizer_state = optimizer.optim.state\n",
    "\n",
    "    for p in reset_params:\n",
    "        param_state = optimizer_state[p]\n",
    "        if len(param_state) == 0: # no state for this param, happens for ZeRo optimizer\n",
    "            continue\n",
    "        for key in optimizer_state_keys:\n",
    "            pruning_fn(param_state[key])  # pruning fn has to be inplace to keep the same keys in the dict\n",
    "            n_total += param_state[key].numel()\n",
    "            n_zeros += torch.sum(param_state[key] == 0).item()\n",
    "\n",
    "    _zeroed = n_zeros / (1e-7 + n_total) * 100\n",
    "    print(f\"Percent of optimizer states zeroed: {_zeroed:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLora Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:56:45.779339Z",
     "iopub.status.busy": "2024-06-02T21:56:45.778937Z",
     "iopub.status.idle": "2024-06-02T21:56:45.782142Z",
     "shell.execute_reply": "2024-06-02T21:56:45.781664Z",
     "shell.execute_reply.started": "2024-06-02T21:56:45.779319Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(r=128, \n",
    "                         target_modules=[\"query_key_value\", \"dense\",\n",
    "                                         \"dense_h_to_4h\", \"dense_4h_to_h\"], \n",
    "                         lora_dropout=0.1, \n",
    "                         lora_alpha=32,)\n",
    "\n",
    "# By default, PEFT initializes LoRA weights with Kaiming-uniform for weight A and zeros for weight B \n",
    "# resulting in an identity transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:58:31.507159Z",
     "iopub.status.busy": "2024-06-02T21:58:31.506522Z",
     "iopub.status.idle": "2024-06-02T21:58:32.054278Z",
     "shell.execute_reply": "2024-06-02T21:58:32.053731Z",
     "shell.execute_reply.started": "2024-06-02T21:58:31.507134Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                          revision=model_revision,\n",
    "                                                          ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:58:32.055442Z",
     "iopub.status.busy": "2024-06-02T21:58:32.055272Z",
     "iopub.status.idle": "2024-06-02T21:58:32.092967Z",
     "shell.execute_reply": "2024-06-02T21:58:32.092461Z",
     "shell.execute_reply.started": "2024-06-02T21:58:32.055425Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,572,864 || all params: 15,640,576 || trainable%: 10.0563\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "\n",
    "lora_model = get_peft_model(model, lora_config)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:58:32.093781Z",
     "iopub.status.busy": "2024-06-02T21:58:32.093618Z",
     "iopub.status.idle": "2024-06-02T21:58:32.097852Z",
     "shell.execute_reply": "2024-06-02T21:58:32.097393Z",
     "shell.execute_reply.started": "2024-06-02T21:58:32.093763Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainable_params = [p for p in lora_model.parameters() if p.requires_grad]\n",
    "lora_params = [p for n, p in lora_model.named_parameters() if p.requires_grad and \"lora_\" in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:58:34.132990Z",
     "iopub.status.busy": "2024-06-02T21:58:34.132535Z",
     "iopub.status.idle": "2024-06-02T21:58:34.136419Z",
     "shell.execute_reply": "2024-06-02T21:58:34.135933Z",
     "shell.execute_reply.started": "2024-06-02T21:58:34.132971Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "optimizer_state_keys = [\"exp_avg\", \"exp_avg_sq\"]\n",
    "\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_iters, num_training_steps=train_iters, num_cycles=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:58:41.434718Z",
     "iopub.status.busy": "2024-06-02T21:58:41.434267Z",
     "iopub.status.idle": "2024-06-02T21:58:41.437590Z",
     "shell.execute_reply": "2024-06-02T21:58:41.437139Z",
     "shell.execute_reply.started": "2024-06-02T21:58:41.434698Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "update_step = 0\n",
    "tokens_seen = 0\n",
    "tokens_seen_before = 0\n",
    "n_lora_restarts = 0\n",
    "n_optimizer_resets = 0\n",
    "\n",
    "reset_optimizer_on_relora = False\n",
    "optimizer_magnitude_pruning = 0.8\n",
    "\n",
    "relora_steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:58:44.660204Z",
     "iopub.status.busy": "2024-06-02T21:58:44.659648Z",
     "iopub.status.idle": "2024-06-02T21:58:44.662780Z",
     "shell.execute_reply": "2024-06-02T21:58:44.662342Z",
     "shell.execute_reply.started": "2024-06-02T21:58:44.660185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cycle_length = scheduler.lr_lambdas[0].keywords['num_training_steps'] // scheduler.lr_lambdas[0].keywords['num_cycles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:58:45.350100Z",
     "iopub.status.busy": "2024-06-02T21:58:45.349644Z",
     "iopub.status.idle": "2024-06-02T21:58:45.358667Z",
     "shell.execute_reply": "2024-06-02T21:58:45.358189Z",
     "shell.execute_reply.started": "2024-06-02T21:58:45.350081Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "\n",
    "lora_model, optimizer, train_dataloader = accelerator.prepare(\n",
    "    lora_model, optimizer, train_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:56:47.953033Z",
     "iopub.status.busy": "2024-06-02T21:56:47.952526Z",
     "iopub.status.idle": "2024-06-02T21:56:47.955325Z",
     "shell.execute_reply": "2024-06-02T21:56:47.954877Z",
     "shell.execute_reply.started": "2024-06-02T21:56:47.953000Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T21:58:49.261706Z",
     "iopub.status.busy": "2024-06-02T21:58:49.261283Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 103/10000 [00:06<06:55, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 25, 'loss/train': 11.018762588500977}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 205/10000 [00:11<06:50, 23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 50, 'loss/train': 10.98302173614502}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 304/10000 [00:15<07:07, 22.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 75, 'loss/train': 10.931792259216309}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 403/10000 [00:19<06:36, 24.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 100, 'loss/train': 10.813177108764648}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 505/10000 [00:23<06:36, 23.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 125, 'loss/train': 10.680569648742676}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 604/10000 [00:28<07:10, 21.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 150, 'loss/train': 10.564942359924316}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 703/10000 [00:32<06:24, 24.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 175, 'loss/train': 10.460001945495605}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 802/10000 [00:36<06:21, 24.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 200, 'loss/train': 10.417052268981934}\n",
      "Performing lora reset at update step 201. Current lr is 7.8515625e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 808/10000 [00:36<07:22, 20.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA reset took 0.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 904/10000 [00:40<06:42, 22.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 225, 'loss/train': 10.390524864196777}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1003/10000 [00:45<07:07, 21.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 250, 'loss/train': 10.36277961730957}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1105/10000 [00:49<06:11, 23.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 275, 'loss/train': 10.314414978027344}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1204/10000 [00:53<06:25, 22.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 300, 'loss/train': 10.295892715454102}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1303/10000 [00:58<06:04, 23.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 325, 'loss/train': 10.263888359069824}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1402/10000 [01:02<06:33, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 350, 'loss/train': 10.251462936401367}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1504/10000 [01:06<06:12, 22.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 375, 'loss/train': 10.215665817260742}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1603/10000 [01:10<05:47, 24.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 400, 'loss/train': 10.236680030822754}\n",
      "Performing lora reset at update step 401. Current lr is 2.7676164400421862e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1609/10000 [01:11<06:26, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA reset took 0.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1705/10000 [01:15<05:51, 23.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 425, 'loss/train': 10.225085258483887}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1804/10000 [01:19<05:58, 22.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 450, 'loss/train': 10.20399284362793}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1903/10000 [01:23<05:34, 24.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 475, 'loss/train': 10.214404106140137}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2005/10000 [01:28<05:49, 22.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 500, 'loss/train': 10.236104011535645}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2056/10000 [01:30<06:02, 21.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing optimizer reset at update step 0. Current lr is 5.260237326031692e-06\n",
      "Percent of optimizer states zeroed: 80.00\n",
      "First step after optimizer reset lr is 5.577718201056375e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2104/10000 [01:32<05:47, 22.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 525, 'loss/train': 10.232243537902832}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2203/10000 [01:36<05:21, 24.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 550, 'loss/train': 10.220515251159668}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2305/10000 [01:41<05:31, 23.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 575, 'loss/train': 10.221592903137207}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2401/10000 [01:45<05:18, 23.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 600, 'loss/train': 10.20496654510498}\n",
      "Performing lora reset at update step 601. Current lr is 5.629448944293127e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2407/10000 [01:45<06:00, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA reset took 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2503/10000 [01:49<05:09, 24.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 625, 'loss/train': 10.207777976989746}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2605/10000 [01:53<05:12, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 650, 'loss/train': 10.160917282104492}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2701/10000 [01:57<05:16, 23.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 675, 'loss/train': 10.168816566467285}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2803/10000 [02:02<04:56, 24.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 700, 'loss/train': 10.182862281799316}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2905/10000 [02:06<04:59, 23.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 725, 'loss/train': 10.157087326049805}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3001/10000 [02:10<05:21, 21.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 750, 'loss/train': 10.188597679138184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3103/10000 [02:15<04:45, 24.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 775, 'loss/train': 10.156176567077637}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3202/10000 [02:19<04:46, 23.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 800, 'loss/train': 10.167394638061523}\n",
      "Performing lora reset at update step 801. Current lr is 6.04413082836085e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3208/10000 [02:19<05:25, 20.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA reset took 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3301/10000 [02:23<04:57, 22.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 825, 'loss/train': 10.141582489013672}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3403/10000 [02:28<04:30, 24.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 850, 'loss/train': 10.143790245056152}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3505/10000 [02:32<04:34, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 875, 'loss/train': 10.169886589050293}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3604/10000 [02:36<04:46, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 900, 'loss/train': 10.150614738464355}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3703/10000 [02:40<04:18, 24.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 925, 'loss/train': 10.145875930786133}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3805/10000 [02:45<04:27, 23.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 950, 'loss/train': 10.155708312988281}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3904/10000 [02:49<04:26, 22.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 975, 'loss/train': 10.157072067260742}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3907/10000 [02:49<04:10, 24.35it/s]"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "completed_steps = 0\n",
    "\n",
    "for step, batch in tqdm(\n",
    "        enumerate(train_dataloader, start=1), total=10000\n",
    "    ):\n",
    "    \n",
    "    output = lora_model(batch[\"input_ids\"], labels=batch[\"input_ids\"])\n",
    "    loss = output.loss\n",
    "    # loss = calculate_loss(batch[\"input_ids\"], logits)\n",
    "    loss = loss / accumulation_steps\n",
    "    accelerator.backward(loss)\n",
    "    if step % accumulation_steps == 0:\n",
    "        accelerator.clip_grad_norm_(lora_model.parameters(), gradient_clipping)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        completed_steps += 1\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        accelerator.print(\n",
    "            {\n",
    "                \"steps\": completed_steps,\n",
    "                \"loss/train\": loss.item() * accumulation_steps,\n",
    "            }\n",
    "        )\n",
    "    if step % accumulation_steps != 0:\n",
    "        continue\n",
    "    can_reset_relora = relora_steps is not None and step // accumulation_steps >= relora_steps\n",
    "\n",
    "    if can_reset_relora and completed_steps % relora_steps == 1:\n",
    "        _lora_reset_time = time.time()\n",
    "        print(f\"Performing lora reset at update step {completed_steps}. Current lr is {optimizer.param_groups[0]['lr']}\")\n",
    "        n_lora_restarts += 1\n",
    "\n",
    "        lora_model = lora_model.merge_and_unload()\n",
    "        lora_model = get_peft_model(lora_model, lora_config)\n",
    "\n",
    "        lora_model = accelerator.prepare(lora_model)\n",
    "                \n",
    "        trainable_params = [p for p in lora_model.parameters() if p.requires_grad]\n",
    "    \n",
    "        optimizer.param_groups[0]['params'] = trainable_params\n",
    "        \n",
    "        _lora_reset_time = time.time() - _lora_reset_time\n",
    "        print(f\"LoRA reset took {_lora_reset_time:.2f}s\")\n",
    "\n",
    "    can_reset_optimizer = relora_steps is not None and step // accumulation_steps >= cycle_length\n",
    "\n",
    "    if can_reset_optimizer and (completed_steps - 0) % cycle_length == 1:\n",
    "        # scheduler should provide a new warmup after the reset\n",
    "        print(f\"Performing optimizer reset at update step {update_step}. Current lr is {optimizer.param_groups[0]['lr']}\")\n",
    "        n_optimizer_resets += 1\n",
    "\n",
    "        optimizer_reset(\n",
    "            optimizer,\n",
    "            reset_params=lora_params,\n",
    "            optimizer_state_keys=optimizer_state_keys,\n",
    "            reset_optimizer_on_relora=reset_optimizer_on_relora,\n",
    "            optimizer_random_pruning=0.0,\n",
    "            optimizer_magnitude_pruning=optimizer_magnitude_pruning,\n",
    "        )\n",
    "    # ##############################\n",
    "\n",
    "    if can_reset_optimizer and (completed_steps - 0) % cycle_length == 2:\n",
    "        print(f\"First step after optimizer reset lr is {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "    lr = optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-rank Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        param.data = param.data.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_iters, num_training_steps=train_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(inputs, logits):\n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_labels = inputs[..., 1:].contiguous()\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    # Calculate per-token loss\n",
    "    loss_fct = CrossEntropyLoss()\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "\n",
    "model, optimizer, train_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 102/2048 [00:10<03:00, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 25, 'loss/train': 10.98653507232666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 202/2048 [00:20<02:50, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 50, 'loss/train': 10.87724781036377}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 302/2048 [00:30<02:41, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 75, 'loss/train': 10.707901954650879}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 402/2048 [00:40<02:32, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 100, 'loss/train': 10.520821571350098}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 502/2048 [00:50<02:23, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 125, 'loss/train': 10.398367881774902}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 602/2048 [01:00<02:14, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 150, 'loss/train': 10.303812026977539}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 702/2048 [01:11<02:05, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 175, 'loss/train': 10.22122859954834}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 802/2048 [01:21<01:56, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 200, 'loss/train': 10.120756149291992}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 902/2048 [01:31<01:46, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 225, 'loss/train': 10.018835067749023}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1002/2048 [01:41<01:38, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 250, 'loss/train': 9.94930362701416}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1102/2048 [01:51<01:27, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 275, 'loss/train': 9.759871482849121}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1202/2048 [02:01<01:18, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 300, 'loss/train': 9.670370101928711}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 1302/2048 [02:11<01:09, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 325, 'loss/train': 9.555130958557129}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1402/2048 [02:21<01:00, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 350, 'loss/train': 9.479826927185059}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1502/2048 [02:31<00:50, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 375, 'loss/train': 9.386810302734375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1602/2048 [02:41<00:41, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 400, 'loss/train': 9.324230194091797}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1702/2048 [02:51<00:32, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 425, 'loss/train': 9.19173526763916}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1802/2048 [03:01<00:23, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 450, 'loss/train': 9.118826866149902}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1902/2048 [03:12<00:13, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 475, 'loss/train': 9.068615913391113}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 2002/2048 [03:22<00:04, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': 500, 'loss/train': 8.984365463256836}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2066it [03:28,  9.90it/s]                          \n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "completed_steps = 0\n",
    "\n",
    "for step, batch in tqdm(\n",
    "        enumerate(train_dataloader, start=1), total=train_iters\n",
    "    ):\n",
    "    \n",
    "    logits = model(batch[\"input_ids\"]).logits\n",
    "    loss = calculate_loss(batch[\"input_ids\"], logits)\n",
    "    loss = loss / accumulation_steps\n",
    "    accelerator.backward(loss)\n",
    "    if step % accumulation_steps == 0:\n",
    "        accelerator.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        completed_steps += 1\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        accelerator.print(\n",
    "            {\n",
    "                \"steps\": completed_steps,\n",
    "                \"loss/train\": loss.item() * accumulation_steps,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
